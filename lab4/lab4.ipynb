{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as nr\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformGenerator:\n",
    "    def __init__(self, a, b):\n",
    "        if not 0 <= a <= b:\n",
    "            raise ValueError('Параметры должны удовлетворять условию 0 <= a <= b')\n",
    "        self._a = a\n",
    "        self._b = b\n",
    "\n",
    "    def next(self):\n",
    "        return nr.uniform(self._a, self._b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonGenerator:\n",
    "    def __init__(self, la):\n",
    "        self._la = la\n",
    "    \n",
    "    def next(self):\n",
    "        return nr.poisson(self._la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, generator):\n",
    "        self._generator = generator\n",
    "        self._receivers = set()\n",
    "\n",
    "    def add_receiver(self, receiver):\n",
    "        self._receivers.add(receiver)\n",
    "\n",
    "    def remove_receiver(self, receiver):\n",
    "        try:\n",
    "            self._receivers.remove(receiver)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    def next_time(self):\n",
    "        return self._generator.next()\n",
    "    \n",
    "    def emit_request(self):\n",
    "        for rec in self._receivers:\n",
    "            rec.receive_request()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queue:\n",
    "    def __init__(self):\n",
    "        self._current_queue_size = 0\n",
    "        self._max_queue_size = 0\n",
    "        \n",
    "    @property\n",
    "    def max_queue_size(self):\n",
    "        return self._max_queue_size\n",
    "\n",
    "    @property\n",
    "    def current_queue_size(self):\n",
    "        return self._current_queue_size\n",
    "    \n",
    "    def add(self):\n",
    "        self._current_queue_size += 1\n",
    "        \n",
    "    def remove(self):\n",
    "        self._current_queue_size -= 1\n",
    "        \n",
    "    def increase_size(self):\n",
    "        self._max_queue_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor(Generator):\n",
    "    def __init__(self, generator, return_probability):\n",
    "        super().__init__(generator)\n",
    "        self._generator = generator\n",
    "        self._processed_requests = 0\n",
    "        self._return_probability = return_probability\n",
    "        self._reentered_requests = 0\n",
    "        self._queue = Queue()\n",
    "        \n",
    "    @property\n",
    "    def processed_requests(self):\n",
    "        return self._processed_requests\n",
    "    \n",
    "    @property\n",
    "    def reentered_requests(self):\n",
    "        return self._reentered_requests\n",
    "    \n",
    "    @property\n",
    "    def queue(self):\n",
    "        return self._queue\n",
    "    \n",
    "    def process(self):\n",
    "        if self._queue.current_queue_size > 0:\n",
    "            self._processed_requests += 1\n",
    "            self._queue.remove()\n",
    "            self.emit_request()\n",
    "            if nr.random_sample() < self._return_probability:\n",
    "                self._reentered_requests += 1\n",
    "                self.receive_request()\n",
    "\n",
    "    def receive_request(self):\n",
    "        self._queue.add()\n",
    "        if self._queue.current_queue_size > self._queue.max_queue_size:\n",
    "            self._queue.increase_size()\n",
    "\n",
    "    def next_time_period(self):\n",
    "        return self._generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, a, b, la, ret_prob):\n",
    "        self._generator = Generator(UniformGenerator(a, b))\n",
    "        self._processor = Processor(PoissonGenerator(la), ret_prob)\n",
    "        self._generator.add_receiver(self._processor)\n",
    "        \n",
    "    def event_based_modelling(self, request_count):\n",
    "        generator = self._generator\n",
    "        processor = self._processor\n",
    "\n",
    "        gen_period = generator.next_time()\n",
    "        proc_period = gen_period + processor.next_time()\n",
    "        while processor.processed_requests < request_count:\n",
    "#         while proc_period < request_count:\n",
    "            if gen_period <= proc_period:\n",
    "                generator.emit_request()\n",
    "                gen_period += generator.next_time()\n",
    "            if gen_period >= proc_period:\n",
    "#                 cur_queue = processor.queue.current_queue_size\n",
    "                processor.process()\n",
    "#                 if processor.queue.current_queue_size == cur_queue:\n",
    "#                     request_count += 1\n",
    "                if processor.queue.current_queue_size > 0:\n",
    "                    proc_period += processor.next_time()\n",
    "                else:\n",
    "                    proc_period = gen_period + processor.next_time()\n",
    "\n",
    "        return (processor.processed_requests, processor.reentered_requests,\n",
    "                processor.queue.max_queue_size, proc_period)\n",
    "\n",
    "    def time_based_modelling(self, request_count, dt):\n",
    "        generator = self._generator\n",
    "        processor = self._processor\n",
    "\n",
    "        gen_period = generator.next_time()\n",
    "        proc_period = gen_period + processor.next_time()\n",
    "        current_time = 0\n",
    "        while processor.processed_requests < request_count:\n",
    "#         while current_time < request_count:\n",
    "            if gen_period <= current_time:\n",
    "                generator.emit_request()\n",
    "                gen_period += generator.next_time()\n",
    "            if current_time >= proc_period:\n",
    "#                 cur_queue = processor.queue.current_queue_size\n",
    "                processor.process()\n",
    "#                 if processor.queue.current_queue_size == cur_queue:\n",
    "#                     request_count += 1\n",
    "                if processor.queue.current_queue_size > 0:\n",
    "                    proc_period += processor.next_time()\n",
    "                else:\n",
    "                    proc_period = gen_period + processor.next_time()\n",
    "            current_time += dt\n",
    "\n",
    "        return (processor.processed_requests, processor.reentered_requests,\n",
    "                processor.queue.max_queue_size, current_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(res, rps):\n",
    "    table = PrettyTable()\n",
    "    table.add_column(\"Вероятность возврата\", rps)\n",
    "    table.add_column(\"Минимальная длина очереди\", res)\n",
    "#     table.add_column(\"Время\", results_t)\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Принцип dt\n",
      "+----------------------+---------------------------+\n",
      "| Вероятность возврата | Минимальная длина очереди |\n",
      "+----------------------+---------------------------+\n",
      "|          0           |            189            |\n",
      "|         0.05         |            222            |\n",
      "|         0.1          |            290            |\n",
      "|         0.2          |            376            |\n",
      "|         0.5          |            708            |\n",
      "|         0.75         |            921            |\n",
      "|         0.9          |            1086           |\n",
      "+----------------------+---------------------------+\n",
      "Событийный принцип\n",
      "+----------------------+---------------------------+\n",
      "| Вероятность возврата | Минимальная длина очереди |\n",
      "+----------------------+---------------------------+\n",
      "|          0           |            199            |\n",
      "|         0.05         |            209            |\n",
      "|         0.1          |            335            |\n",
      "|         0.2          |            401            |\n",
      "|         0.5          |            701            |\n",
      "|         0.75         |            919            |\n",
      "|         0.9          |            1079           |\n",
      "+----------------------+---------------------------+\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "b = 10\n",
    "la = 6\n",
    "rp = 0.1\n",
    "# modelev1 = Model(a, b, la, 0)\n",
    "# modeltm1 = Model(a, b, la, 0)\n",
    "# modelev2 = Model(a, b, la, rp)\n",
    "# modeltm2 = Model(a, b, la, rp)\n",
    "\n",
    "rps = [0, 0.05, 0.1, 0.2, 0.5, 0.75, 0.9]\n",
    "res_t = []\n",
    "res_e = []\n",
    "for i in range(len(rps)):\n",
    "    modelt = Model(a, b, la, rps[i])\n",
    "    modele = Model(a, b, la, rps[i])\n",
    "    processedt, reenteredt, queue_sizet, timet = modelt.time_based_modelling(1000, 0.001)\n",
    "    processede, reenterede, queue_sizee, timee = modele.event_based_modelling(1000)\n",
    "    res_t.append(queue_sizet)\n",
    "    res_e.append(queue_sizee)\n",
    "print(\"Принцип dt\")\n",
    "print_results(res_t, rps)\n",
    "print(\"Событийный принцип\")\n",
    "print_results(res_e, rps)\n",
    "\n",
    "# print(modelev1.event_based_modelling(1000))\n",
    "# print(modeltm1.time_based_modelling(1000, 0.001))\n",
    "# print(modelev2.event_based_modelling(1000))\n",
    "# print(modeltm2.time_based_modelling(1000, 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
