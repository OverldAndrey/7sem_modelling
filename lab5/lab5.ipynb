{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as nr\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniformGenerator:\n",
    "    def __init__(self, a, b):\n",
    "        if not 0 <= a <= b:\n",
    "            raise ValueError('Параметры должны удовлетворять условию 0 <= a <= b')\n",
    "        self._a = a\n",
    "        self._b = b\n",
    "\n",
    "    def next(self):\n",
    "        return nr.uniform(self._a, self._b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoissonGenerator:\n",
    "    def __init__(self, la):\n",
    "        self._la = la\n",
    "    \n",
    "    def next(self):\n",
    "        return nr.poisson(self._la)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstGenerator:\n",
    "    def __init__(self, c):\n",
    "        self._c = c\n",
    "        \n",
    "    def next(self):\n",
    "        return self._c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator:\n",
    "    def __init__(self, generator):\n",
    "        self._generator = generator\n",
    "        self._receivers = []\n",
    "        self._generated_requests = 0\n",
    "        self._next_event_time = 0\n",
    "        \n",
    "    @property\n",
    "    def next_event_time(self):\n",
    "        return self._next_event_time\n",
    "    \n",
    "    @next_event_time.setter\n",
    "    def next_event_time(self, time):\n",
    "        self._next_event_time = time\n",
    "        \n",
    "    @property\n",
    "    def generated_requests(self):\n",
    "        return self._generated_requests\n",
    "        \n",
    "\n",
    "    def add_receiver(self, receiver):\n",
    "        if receiver not in self._receivers:\n",
    "            self._receivers.append(receiver)\n",
    "\n",
    "    def remove_receiver(self, receiver):\n",
    "        try:\n",
    "            self._receivers.remove(receiver)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    \n",
    "    def next_time(self):\n",
    "        return self._generator.next()\n",
    "    \n",
    "    def emit_request(self):\n",
    "        self._generated_requests += 1\n",
    "        for rec in self._receivers:\n",
    "            if rec.receive_request():\n",
    "                return rec\n",
    "        else:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Queue:\n",
    "    def __init__(self, max_size):\n",
    "        self._queued = 0\n",
    "        self._max_queue_size = max_size\n",
    "        self._queue_size = max_size\n",
    "        \n",
    "    @property\n",
    "    def max_queue_size(self):\n",
    "        return self._max_queue_size\n",
    "\n",
    "    @property\n",
    "    def current_queue_size(self):\n",
    "        return self._queue_size\n",
    "    \n",
    "    @property\n",
    "    def queued(self):\n",
    "        return self._queued\n",
    "    \n",
    "    def add(self):\n",
    "        self._queued += 1\n",
    "        \n",
    "    def remove(self):\n",
    "        self._queued -= 1\n",
    "        \n",
    "    def increase_size(self):\n",
    "        self._queue_size += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processor(Generator):\n",
    "    def __init__(self, generator, max_queue_size = 0, return_probability = 0.0):\n",
    "        super().__init__(generator)\n",
    "        self._generator = generator\n",
    "        self._processed_requests = 0\n",
    "        self._return_probability = return_probability\n",
    "        self._reentered_requests = 0\n",
    "        self._queue = Queue(max_queue_size)\n",
    "        \n",
    "    @property\n",
    "    def processed_requests(self):\n",
    "        return self._processed_requests\n",
    "    \n",
    "    @property\n",
    "    def reentered_requests(self):\n",
    "        return self._reentered_requests\n",
    "    \n",
    "    @property\n",
    "    def queue(self):\n",
    "        return self._queue\n",
    "    \n",
    "    def process(self):\n",
    "        if self._queue.queued > 0:\n",
    "            self._processed_requests += 1\n",
    "            self._queue.remove()\n",
    "            self.emit_request()\n",
    "            if nr.random_sample() < self._return_probability:\n",
    "                self._reentered_requests += 1\n",
    "                self.receive_request()\n",
    "\n",
    "    def receive_request(self):\n",
    "        if self._queue.max_queue_size == 0:\n",
    "            if self._queue.queued >= self._queue.current_queue_size:\n",
    "                self._queue.increase_size()\n",
    "            self._queue.add()\n",
    "            return True\n",
    "        elif self._queue.queued < self._queue.current_queue_size:\n",
    "            self._queue.add()\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def next_time_period(self):\n",
    "        return self._generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelling(max_requests = 300):\n",
    "    cl_m = 10\n",
    "    cl_d = 2\n",
    "    op1_m = 20\n",
    "    op1_d = 5\n",
    "    op2_m = 40\n",
    "    op2_d = 10\n",
    "    op3_m = 40\n",
    "    op3_d = 20\n",
    "    comp1_c = 15\n",
    "    comp2_c = 30\n",
    "    \n",
    "    clients = Generator(UniformGenerator(cl_m - cl_d, cl_m + cl_d))\n",
    "    op1 = Processor(UniformGenerator(op1_m - op1_d, op1_m + op1_d), 1)\n",
    "    op2 = Processor(UniformGenerator(op2_m - op2_d, op2_m + op2_d), 1)\n",
    "    op3 = Processor(UniformGenerator(op3_m - op3_d, op3_m + op3_d), 1)\n",
    "    comp1 = Processor(ConstGenerator(comp1_c))\n",
    "    comp2 = Processor(ConstGenerator(comp2_c))\n",
    "    \n",
    "    clients.add_receiver(op1)\n",
    "    clients.add_receiver(op2)\n",
    "    clients.add_receiver(op3)\n",
    "    op1.add_receiver(comp1)\n",
    "    op2.add_receiver(comp1)\n",
    "    op3.add_receiver(comp2)\n",
    "    \n",
    "    nodes = [clients, op1, op2, op3, comp1, comp2]\n",
    "    for n in nodes:\n",
    "        n.next_event_time = 0\n",
    "        \n",
    "    aborted = 0\n",
    "    \n",
    "    clients.next_event_time = clients.next_time()\n",
    "    op1.next_event_time = op1.next_time()\n",
    "    \n",
    "    while clients.generated_requests < max_requests:\n",
    "        current_time = clients.next_event_time\n",
    "        for n in nodes:\n",
    "            if 0 < n.next_event_time < current_time:\n",
    "                current_time = n.next_event_time\n",
    "                \n",
    "        for n in nodes:\n",
    "            if current_time == n.next_event_time:\n",
    "                if not isinstance(n, Processor):\n",
    "                    assigned_processor = clients.emit_request()\n",
    "                    if assigned_processor is not None:\n",
    "                        assigned_processor.next_event_time = (current_time +\n",
    "                                                              assigned_processor.next_time())\n",
    "                    else:\n",
    "                        aborted += 1\n",
    "                    clients.next_event_time = current_time + clients.next_time()\n",
    "                else:\n",
    "                    n.process()\n",
    "                    if n.queue.queued == 0:\n",
    "                        n.next_event_time = 0\n",
    "                    else:\n",
    "                        n.next_event_time = current_time + n.next_time()\n",
    "                        \n",
    "    return [aborted, aborted / max_requests]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(aborted, aborted_p):\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"\", \"Число отказов\", \"Вероятность отказа, %\"]\n",
    "    table.add_row([\"min\", aborted[0], round(aborted_p[0] * 100, 3)])\n",
    "    table.add_row([\"max\", aborted[1], round(aborted_p[1] * 100, 3)])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---------------+-----------------------+\n",
      "|     | Число отказов | Вероятность отказа, % |\n",
      "+-----+---------------+-----------------------+\n",
      "| min |       59      |         19.667        |\n",
      "| max |       68      |         22.667        |\n",
      "+-----+---------------+-----------------------+\n"
     ]
    }
   ],
   "source": [
    "aborted = []\n",
    "aborted_p = []\n",
    "\n",
    "for i in range(10):\n",
    "    res = modelling(300)\n",
    "    aborted.append(res[0])\n",
    "    aborted_p.append(res[1])\n",
    "\n",
    "print_results([min(aborted), max(aborted)], [min(aborted_p), max(aborted_p)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
